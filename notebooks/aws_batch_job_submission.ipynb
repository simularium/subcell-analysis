{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10810799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import getpass\n",
    "import numpy as np\n",
    "from preconfig import Preconfig\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "from simulariumio.cytosim import CytosimConverter, CytosimData, CytosimObjectInfo\n",
    "from simulariumio import MetaData, DisplayData, DISPLAY_TYPE, ModelMetaData, InputFileData, ScatterPlotData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548a861",
   "metadata": {},
   "source": [
    "# 1. Upload config files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b518e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preconfig class allows us to parse a template file and generate a list of config files.\n",
    "# Two loops puts the generated config files for a given number of repeats in S3.\n",
    "preconfig = Preconfig()\n",
    "path_to_template = '../templates/vary_compress_rate.cym.tpl'\n",
    "configs = preconfig.parse(path_to_template,{})\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket = 'cytosim-working-bucket'\n",
    "num_repeats = 5\n",
    "job_names = []\n",
    "buffered = np.empty((len(configs)), dtype=object)\n",
    "for index, config in enumerate(configs):\n",
    "    job_name = config[:-4]\n",
    "    job_names.append(job_name)\n",
    "    for repeat in range(num_repeats):\n",
    "        opened_config = open(config, \"rb\")\n",
    "        config_name = f'{job_name}/config/{job_name}_{repeat}.cym' \n",
    "        s3_client.put_object(Bucket=bucket, Key=config_name, Body=opened_config)\n",
    "job_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2a431",
   "metadata": {},
   "source": [
    "# 2a. Specify job definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d457054",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_definition_arn = \"job_definition_arn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5adf71a",
   "metadata": {},
   "source": [
    "# 2b. Create and register job definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ce769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for a job definition\n",
    "from container_collection.batch.register_batch_job import register_batch_job\n",
    "job_definition_name = \"karthikv_cytosim_varycompressrate\"\n",
    "image = \"simularium/cytosim:latest\"\n",
    "vcpus = 1\n",
    "memory = 7000\n",
    "bucket_name = \"s3://cytosim-working-bucket/\"\n",
    "simulation_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "account = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make batch job is a function that takes in the parameters below and returns a dictionary that is used to create a batch job. \n",
    "def make_batch_job(\n",
    "    name: str,\n",
    "    image: str,\n",
    "    account: str,\n",
    "    region: str,\n",
    "    user: str,\n",
    "    vcpus: int,\n",
    "    memory: int,\n",
    "    prefix: str\n",
    ") -> dict:\n",
    "    return {\n",
    "    \"jobDefinitionName\": f\"{user}-{name}\",\n",
    "    \"type\": \"container\",\n",
    "    \"containerProperties\": {\n",
    "        \"image\": image,\n",
    "        \"vcpus\": vcpus,\n",
    "        \"memory\": memory,\n",
    "        \"environment\": [\n",
    "            {\"name\": \"SIMULATION_TYPE\", \"value\": \"AWS\"},\n",
    "            {\"name\": \"S3_INPUT_URL\", \"value\": bucket_name},\n",
    "            {\"name\": \"SIMULATION_NAME\", \"value\": simulation_name}\n",
    "        ],\n",
    "        \"jobRoleArn\": f\"arn:aws:iam::{account}:role/BatchJobRole\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating job definitions with make_batch_job\n",
    "# Submitting job definitions with register_batch_job\n",
    "jobs = np.empty(len(configs))\n",
    "job_definitions = np.empty((len(configs)), dtype=object)\n",
    "for index in range(len(configs)):\n",
    "    print(index)\n",
    "    simulation_name = job_names[index]\n",
    "    print(simulation_name)\n",
    "    job_definition = make_batch_job(f\"cytosim-varycompressrate-{str(index)}\", 'simularium/cytosim:latest', account, 'us-west-2', 'karthikv', 1, 7000, 's3://cytosim-working-bucket/')\n",
    "    registered_jd = register_batch_job(job_definition)\n",
    "    job_definitions[index] = registered_jd\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f119ae8",
   "metadata": {},
   "source": [
    "# 3. Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit batch job allows us to submit a batch job with a given job definition and job name.\n",
    "from container_collection.batch.submit_batch_job import submit_batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16255a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_configs = configs[:4]\n",
    "new_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for our batch job [size indicates our desired number of repeats]\n",
    "job_name = \"cytosim-varycompressrate\"\n",
    "user = \"karthikv\"\n",
    "queue = \"general_on_demand\"\n",
    "size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_configs\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to submit our batch jobs [index * size for total number of simulations]\n",
    "for index in range(len(new_configs)):\n",
    "    print(index)\n",
    "    print(f'{job_name}-completerun-config{index}')\n",
    "    submit_batch_job(name=f'{job_name}-completerun-config{index}', job_definition_arn=job_definitions[index],user=user,queue=queue,size=size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f488ac6",
   "metadata": {},
   "source": [
    "# 4. Monitor job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eff920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check job status, print progress bar\n",
    "from container_collection.batch.check_batch_job import check_batch_job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e15d9b",
   "metadata": {},
   "source": [
    "# 5. Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd466e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subcell_analysis.cytosim.post_process_cytosim import create_dataframes_for_repeats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf465a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'cytosim-working-bucket'\n",
    "num_repeats = 5\n",
    "configs = ['vary_compress_rate0006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb21524",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataframes_for_repeats(bucket_name, num_repeats, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subcell_analysis.compression_workflow_runner import run_workflow,  plot_metric, plot_metric_list\n",
    "from subcell_analysis.compression_analysis import (\n",
    "    COMPRESSIONMETRIC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Run metric calculations on repeats.\n",
    "outputs = [None] * num_repeats\n",
    "for repeat in range(num_repeats):\n",
    "    all_output = pd.read_csv(f'dataframes/actin-forces0_{repeat}.csv')\n",
    "    outputs[repeat] = run_workflow(all_output, [COMPRESSIONMETRIC.PEAK_ASYMMETRY, COMPRESSIONMETRIC.AVERAGE_PERP_DISTANCE, COMPRESSIONMETRIC.NON_COPLANARITY, COMPRESSIONMETRIC.TOTAL_FIBER_TWIST, COMPRESSIONMETRIC.SUM_BENDING_ENERGY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "metrics = [COMPRESSIONMETRIC.AVERAGE_PERP_DISTANCE, COMPRESSIONMETRIC.TOTAL_FIBER_TWIST, COMPRESSIONMETRIC.SUM_BENDING_ENERGY, COMPRESSIONMETRIC.PEAK_ASYMMETRY, COMPRESSIONMETRIC.NON_COPLANARITY]\n",
    "for metric in metrics:\n",
    "    fig, ax = plt.subplots()\n",
    "    for repeat in range(num_repeats):\n",
    "        metric_by_time = outputs[repeat].groupby([\"time\"])[metric].mean()\n",
    "        ax.plot(metric_by_time, label=f\"repeat {repeat}\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.set_ylabel(metric.value)\n",
    "    ax.set_title(f\"{metric.value} by time\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3bdcbb6",
   "metadata": {},
   "source": [
    "## 6. Generate Simularium Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subcell_analysis.cytosim.post_process_cytosim import cytosim_to_simularium\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_client.download_file(\"cytosim-working-bucket\", \"vary_compress_rate0006/outputs/2/fiber_segment_curvature.txt\", \"fiber_segment_curvature.txt\")\n",
    "input_data = cytosim_to_simularium(\"fiber_segment_curvature.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cytosim_converter = CytosimConverter(input_data)\n",
    "repeat = 0\n",
    "for metric in metrics:\n",
    "    metric_by_time = outputs[repeat].groupby([\"time\"])[metric].mean()\n",
    "    cytosim_converter.add_plot(\n",
    "    ScatterPlotData(\n",
    "        title=f\"{metric} over time\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=metric.value,\n",
    "        xtrace=np.arange(len(metric_by_time))*1E-5,\n",
    "        ytraces={\n",
    "            f\"repeat {repeat}\": metric_by_time,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "cytosim_converter.save(\"vary_compress_rate_0006_replicate0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: All repetitions in same simularium visualization???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subcell-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d558620a2403be4c2958b608989a9fc85658cf9867c13a1b5b0a1011c0ea0956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
