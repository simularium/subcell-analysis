{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import readdy\n",
    "import boto3\n",
    "import numpy as np\n",
    "import argparse\n",
    "from subcell_analysis.readdy import (\n",
    "    ReaddyLoader,\n",
    "    ReaddyPostProcessor,\n",
    ")\n",
    "from subcell_analysis.compression_workflow_runner import compression_metrics_workflow,  plot_metric, plot_metric_list\n",
    "from subcell_analysis.compression_analysis import (\n",
    "    COMPRESSIONMETRIC,\n",
    ")\n",
    "from subcell_analysis.cytosim.post_process_cytosim import create_dataframes_for_repeats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"../data/readdy_h5_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"actin_compression_velocity_15_0.h5\"\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.download_file('readdy-working-bucket', 'outputs/actin_compression_velocity=15_0.h5', f'{save_folder}/{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_path = f'{save_folder}/{file_name}'\n",
    "\n",
    "post_processor = ReaddyPostProcessor(\n",
    "    ReaddyLoader(h5_file_path).trajectory(),\n",
    "    box_size=600.0 * np.ones(3),\n",
    ")\n",
    "fiber_chain_ids = post_processor.linear_fiber_chain_ids(\n",
    "    start_particle_phrases=[\"pointed\"],\n",
    "    other_particle_types=[\n",
    "        \"actin#\",\n",
    "        \"actin#ATP_\",\n",
    "        \"actin#mid_\",\n",
    "        \"actin#mid_ATP_\",\n",
    "        \"actin#fixed_\",\n",
    "        \"actin#fixed_ATP_\",\n",
    "        \"actin#mid_fixed_\",\n",
    "        \"actin#mid_fixed_ATP_\",\n",
    "        \"actin#barbed_\",\n",
    "        \"actin#barbed_ATP_\",\n",
    "        \"actin#fixed_barbed_\",\n",
    "        \"actin#fixed_barbed_ATP_\",\n",
    "    ],\n",
    "    polymer_number_range=5,\n",
    ")\n",
    "axis_positions, _ = post_processor.linear_fiber_axis_positions(\n",
    "    fiber_chain_ids=fiber_chain_ids,\n",
    "    ideal_positions=np.array(\n",
    "        [\n",
    "            [24.738, 20.881, 26.671],\n",
    "            [27.609, 24.061, 27.598],\n",
    "            [30.382, 21.190, 25.725],\n",
    "        ]\n",
    "    ),\n",
    "    ideal_vector_to_axis=np.array(\n",
    "        [-0.01056751, -1.47785105, -0.65833209],\n",
    "    ),\n",
    ")\n",
    "fiber_points = post_processor.linear_fiber_control_points(\n",
    "    axis_positions=axis_positions,\n",
    "    segment_length=10.0,\n",
    ")\n",
    "print(fiber_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiber_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subcell_analysis.compression_workflow_runner import compression_metrics_workflow,  plot_metric, plot_metric_list\n",
    "from subcell_analysis.compression_analysis import (\n",
    "    COMPRESSIONMETRIC,\n",
    ")\n",
    "from subcell_analysis.cytosim.post_process_cytosim import create_dataframes_for_repeats\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(fiber_points[0][0])\n",
    "arr.shape\n",
    "\n",
    "\n",
    "def array_to_dataframe(arr):\n",
    "    # Reshape the array to remove the singleton dimensions\n",
    "    arr = np.squeeze(arr)\n",
    "\n",
    "    # Reshape the array to have dimensions (timepoints * 50, 3)\n",
    "    reshaped_arr = arr.reshape(-1, 3)\n",
    "\n",
    "    # Create a DataFrame with timepoint and fiber point as multi-index\n",
    "    timepoints = np.repeat(range(arr.shape[0]), 50)\n",
    "    fiber_points = np.tile(range(50), arr.shape[0])\n",
    "\n",
    "    df = pd.DataFrame(reshaped_arr)\n",
    "    df['time'] = timepoints\n",
    "    df['id'] = fiber_points\n",
    "\n",
    "    df.set_index(['time', 'id'], inplace=True)\n",
    "\n",
    "    return df\n",
    "df_points = array_to_dataframe(arr)\n",
    "df_points.reset_index(inplace=True)\n",
    "df_points.rename(columns= {0:'x', 1:'y', 2:'z'}, inplace=True)\n",
    "single_timepoint = df_points[df_points['time'] == 0]\n",
    "single_timepoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points\n",
    "\n",
    "df_points['time'].unique()\n",
    "df_points.to_csv(\"../dataframes/readdy_processed_data.csv\", index=False)\n",
    "#df_points.to_csv(\"../dataframes/readdy_processed_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points = pd.read_csv(\"../dataframes/readdy_processed_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Assuming you have a DataFrame named 'df_points' with columns 'time', 'id', 'x', 'y', and 'z'\n",
    "# df_points = pd.DataFrame(...)  # Your data goes here\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get unique timestamps in the data\n",
    "timestamps = df_points['time'].unique()\n",
    "\n",
    "# Function to update the plot at each time step\n",
    "def update_plot(time_step, ax=ax):\n",
    "    ax.cla()  # Clear previous plot\n",
    "\n",
    "    # Filter the data for the current timestamp\n",
    "    data_at_time = df_points[df_points['time'] == timestamps[time_step]]\n",
    "\n",
    "    # Plot the points at the current time step\n",
    "    ax.scatter(data_at_time['x'], data_at_time['y'], data_at_time['z'], c='r', marker='o')\n",
    "\n",
    "    # Set plot labels and title\n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    ax.set_zlabel('Z Position')\n",
    "    ax.set_title(f'Time: {timestamps[time_step]}')\n",
    "    ax.set_xlim([-300, 300])\n",
    "    ax.set_ylim([-15, 15])\n",
    "    ax.set_zlim([-10, 30])\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "# Create the animation\n",
    "update_plot(-1) \n",
    "\n",
    "# If you want to save the animation to a file\n",
    "# animation.save('3d_animation.mp4', writer='ffmpeg')\n",
    "#animation.save('3d_animation_frames/frame_{:04d}.png', writer='pillow', fps=1)\n",
    "\n",
    "# Show the plot (If you don't want to save it)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "metrics = [COMPRESSIONMETRIC.NON_COPLANARITY, COMPRESSIONMETRIC.PEAK_ASYMMETRY, COMPRESSIONMETRIC.TOTAL_FIBER_TWIST]\n",
    "df_points = compression_metrics_workflow(df_points, [COMPRESSIONMETRIC.NON_COPLANARITY, COMPRESSIONMETRIC.PEAK_ASYMMETRY, COMPRESSIONMETRIC.TOTAL_FIBER_TWIST])\n",
    "df_points.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    fig, ax = plt.subplots()\n",
    "    print(metric.value)\n",
    "    metric_by_time = df_points.groupby([\"time\"])[metric.value].mean()\n",
    "    ax.plot(metric_by_time, label=f\"metric = {metric.value}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Outputs for All Readdy Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_velocities = [4.7, 15, 47, 150]\n",
    "iterations = [0, 1, 2]  \n",
    "empty_array = np.zeros((len(compression_velocities), len(iterations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/readdy_h5_files\")\n",
    "data_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, velocity in enumerate(compression_velocities):\n",
    "    for iteration in iterations:\n",
    "        new_file_path = f'{data_dir}/readdy_actin_compression_velocity_{velocity}_{iteration}.h5'\n",
    "        print(f\"Downloading file: {new_file_path}\")\n",
    "        response = s3.download_file('readdy-working-bucket', f'outputs/actin_compression_velocity={velocity}_{iteration}.h5', new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiber_points = np.empty((4, 3), dtype=object)\n",
    "\n",
    "for index, velocity in enumerate(compression_velocities):\n",
    "    for iteration in iterations:\n",
    "        new_file_path = f'{data_dir}/actin_compression_velocity_{velocity}_{iteration}.h5'\n",
    "        post_processor = ReaddyPostProcessor(\n",
    "        ReaddyLoader(new_file_path).trajectory(),\n",
    "        box_size=600.0 * np.ones(3),\n",
    "        )\n",
    "        fiber_chain_ids = post_processor.linear_fiber_chain_ids(\n",
    "        start_particle_phrases=[\"pointed\"],\n",
    "        other_particle_types=[\n",
    "            \"actin#\",\n",
    "            \"actin#ATP_\",\n",
    "            \"actin#mid_\",\n",
    "            \"actin#mid_ATP_\",\n",
    "            \"actin#fixed_\",\n",
    "            \"actin#fixed_ATP_\",\n",
    "            \"actin#mid_fixed_\",\n",
    "            \"actin#mid_fixed_ATP_\",\n",
    "            \"actin#barbed_\",\n",
    "            \"actin#barbed_ATP_\",\n",
    "            \"actin#fixed_barbed_\",\n",
    "            \"actin#fixed_barbed_ATP_\",\n",
    "        ],\n",
    "        polymer_number_range=5,\n",
    "        )\n",
    "        axis_positions, _ = post_processor.linear_fiber_axis_positions(\n",
    "            fiber_chain_ids=fiber_chain_ids,\n",
    "            ideal_positions=np.array(\n",
    "                [\n",
    "                    [24.738, 20.881, 26.671],\n",
    "                    [27.609, 24.061, 27.598],\n",
    "                    [30.382, 21.190, 25.725],\n",
    "                ]\n",
    "            ),\n",
    "            ideal_vector_to_axis=np.array(\n",
    "                [-0.01056751, -1.47785105, -0.65833209],\n",
    "            ),\n",
    "        )\n",
    "        fiber_points[index][iteration] = post_processor.linear_fiber_control_points(\n",
    "            axis_positions=axis_positions,\n",
    "            segment_length=10.0,\n",
    "        )\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save processed fiber_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(\"../data/dataframes/\")\n",
    "df_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, velocity in enumerate(compression_velocities):\n",
    "    for iteration in iterations:\n",
    "        print(index, iteration)\n",
    "        if index == 1 and iteration == 2:  #  TODO: check why this is happening\n",
    "            break\n",
    "        arr = np.array(fiber_points[index][iteration])\n",
    "        print(arr.shape)\n",
    "        df_points = array_to_dataframe(arr)\n",
    "        df_points.reset_index(inplace=True)\n",
    "        df_points.rename(columns= {0:'xpos', 1:'ypos', 2:'zpos'}, inplace=True)\n",
    "        df_points.to_csv(f\"{df_path}/actin_compression_velocity_{velocity}.{iteration}.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting from Reading from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(\"../data/dataframes/\")\n",
    "df_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataframes = np.empty((len(compression_velocities), len(iterations)), dtype = object)\n",
    "for index, velocity in enumerate(compression_velocities):\n",
    "    for iteration in iterations:\n",
    "        if index == 1 and iteration == 2:\n",
    "            break\n",
    "        processed_dataframes[index][iteration] = pd.read_csv(f\"{df_path}/readdy_actin_compression_velocity_{velocity}_repeat_{iteration}.csv\")\n",
    "        print(index, iteration, processed_dataframes[index][iteration].shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics for processed dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, velocity in enumerate(compression_velocities):\n",
    "    for iteration in iterations:\n",
    "        print(index, iteration)\n",
    "        if (index == 1 and iteration == 2):\n",
    "            break\n",
    "        processed_dataframes[index][iteration] = compression_metrics_workflow(processed_dataframes[index][iteration], [COMPRESSIONMETRIC.NON_COPLANARITY, COMPRESSIONMETRIC.PEAK_ASYMMETRY, COMPRESSIONMETRIC.TOTAL_FIBER_TWIST])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataframes[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot calculated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = Path(\"../figures/readdy_metrics\")\n",
    "figure_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =  [COMPRESSIONMETRIC.NON_COPLANARITY, COMPRESSIONMETRIC.PEAK_ASYMMETRY, COMPRESSIONMETRIC.TOTAL_FIBER_TWIST]\n",
    "compression_velocities = [4.7, 15, 47, 150]\n",
    "for metric in metrics:\n",
    "    fig, axs = plt.subplots(1, len(compression_velocities), figsize=(len(compression_velocities) * 5, 5), dpi=300, sharey=True, sharex=True)\n",
    "    for index, velocity in enumerate(compression_velocities):\n",
    "        print(metric.value)\n",
    "        for iteration in iterations:\n",
    "            if (index == 1 and iteration == 2):\n",
    "                continue\n",
    "            metric_by_time = processed_dataframes[index][iteration].groupby([\"time\"])[metric.value].mean()\n",
    "            axs[index].plot(metric_by_time, label=f\"iteration = {iteration}\")\n",
    "        axs[index].set_title(f\"compression velocity = {velocity}\")\n",
    "        axs[index].legend()\n",
    "        if index == 0:\n",
    "            axs[index].set_ylabel(metric.value)\n",
    "    fig.suptitle(f\"Readdy\")\n",
    "    fig.supxlabel(\"time\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(f\"{figure_path}/actin_compression_all_velocities_{metric.value}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Assuming you have a DataFrame named 'df_points' with columns 'time', 'id', 'x', 'y', and 'z'\n",
    "# df_points = pd.DataFrame(...)  # Your data goes here\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get unique timestamps in the data\n",
    "timestamps = processed_dataframes[0][0]['time'].unique()\n",
    "\n",
    "# Function to update the plot at each time step\n",
    "def update_plot(time_step, ax=ax):\n",
    "    ax.cla()  # Clear previous plot\n",
    "\n",
    "    # Filter the data for the current timestamp\n",
    "    data_at_time = df_points[df_points['time'] == timestamps[time_step]]\n",
    "\n",
    "    # Plot the points at the current time step\n",
    "    ax.scatter(data_at_time['x'], data_at_time['y'], data_at_time['z'], c='r', marker='o')\n",
    "\n",
    "    # Set plot labels and title\n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    ax.set_zlabel('Z Position')\n",
    "    ax.set_title(f'Time: {timestamps[time_step]}')\n",
    "    ax.set_xlim([-300, 300])\n",
    "    ax.set_ylim([-15, 15])\n",
    "    ax.set_zlim([-10, 30])\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update_plot, frames=len(timestamps), fargs=(ax,))\n",
    "ani.save('ani.txt')\n",
    "# If you want to save the animation to a file\n",
    "# animation.save('3d_animation.mp4', writer='ffmpeg')\n",
    "#animation.save('3d_animation_frames/frame_{:04d}.png', writer='pillow', fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readdy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:38:11) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "81e20c206800988725223b8d297cc7293aedd8f169ec800b58f2fdd6e2f42f5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
